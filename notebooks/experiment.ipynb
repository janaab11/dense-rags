{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73f88f8-68f4-4668-bebd-ca91d559fe51",
   "metadata": {},
   "source": [
    "# RAG Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa58c8e0-f2fd-4a72-a19c-d60703bc5506",
   "metadata": {},
   "source": [
    "We start by defining a few constants and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "7226727b-61d3-4406-a196-3b1bee80a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../datasets/books/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "3668d9f0-3631-4d38-90fe-098ba2333935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DB_PATH = os.path.join(DATASET_DIR, \"vector_db\")\n",
    "EVAL_PATH = os.path.join(DATASET_DIR, \"eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f690370c-7691-430a-8a8e-48b1d02f0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, RetrievalQA, HypotheticalDocumentEmbedder\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings, OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "467bca83-9704-4c28-99f1-6d7a2045961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\", getpass.getpass())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658fdfa-fcfd-48e5-b033-234b149e2ac1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1351e51-84fc-458e-8179-9deed2d9b9b8",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada6331-1512-4180-89ed-2df4d7f5f2cd",
   "metadata": {},
   "source": [
    "### Naive\n",
    "\n",
    "Standard retriever from Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "9b6d2392-7906-4b6f-b33f-e6cad36ea31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5a32ad1e-82c9-49b5-869b-7c886f0ba7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_retriever = Chroma(persist_directory=DB_PATH, embedding_function=embeddings).as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3084d-9894-4a6c-98b8-47d1ae863e47",
   "metadata": {},
   "source": [
    "### Hyde (Hypothetical Document Embeddings)\n",
    "\n",
    "HyDE retriever from Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e6e8d7dd-d038-49b3-bf04-6a38f2a92ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "c46bf42f-c273-478b-be09-52522789d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"Please answer the question \\nQuestion: {question}\\nAnswer:\"\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n",
    "\n",
    "generative_model = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "retriever_chain = LLMChain(llm=generative_model, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "7724a434-493c-4512-a78b-e66ccb0c9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HypotheticalDocumentEmbedder(\n",
    "    llm_chain=retriever_chain, base_embeddings=base_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "42100ad0-511b-464f-8a48-dbb4b3b541c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_retriever = Chroma(persist_directory=DB_PATH, embedding_function=embeddings).as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da26c368-59ba-4582-8173-c1ef9fdc3f3f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30939b-5216-4466-ac98-9d39e7b998c9",
   "metadata": {},
   "source": [
    "## Generation\n",
    "\n",
    "Retriever uses Query to get Context Documents from the Vector Store. Both Query and Context are used to prompt a generative model for the Answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b90874-cfe9-4ec0-804a-694dd0976c9b",
   "metadata": {},
   "source": [
    "Notice, the better retrieval with HyDE - more relevant documents are seemingly retrieved. (But this is a sample size of 1!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8bd53976-91e2-40a8-86ca-7a82bfe9d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "5ffbd133-a71c-4420-a1e3-8afa672ee915",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:'''\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"question\", \"context\"], template=prompt_template)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3002f832-fe86-480a-8a21-5f0717421fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chain(retriever, llm, prompt):\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt},\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf234df1-544c-4868-b517-74b4d5b7e507",
   "metadata": {},
   "source": [
    "### Naive output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "86813290-26a7-4ba4-b5b6-e056f1d8cfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reasons to Stay Alive by Matt Haig is a good book for adults with depression. It is an inspiring memoir of overcoming depression and finding reasons to appreciate life. The book provides encouragement and insight for those struggling with mental illness.'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cost/compute intensive\n",
    "\n",
    "question = \"What is a good book for adults with depression?\"\n",
    "naive_rag = get_chain(naive_retriever, llm, prompt)\n",
    "result = naive_rag.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8732e-180e-403d-ab4b-9bb3bf4e3b5c",
   "metadata": {},
   "source": [
    "### HyDE output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "d948016d-44f7-41fb-9e60-096681c860a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Mindful Way through Depression: Freeing Yourself from Chronic Unhappiness is a good book for adults with depression as it offers authoritative, clinically proven self-help methods to reduce chronic unhappiness. Dianetics: The Modern Science of Mental Health also provides insight into eradicating the source of stress, anxiety, and depression for a happier life. Reasons to Stay Alive is an accessible and inspiring memoir of overcoming depression, offering hope and encouragement for those struggling with mental illness.'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cost/compute intensive\n",
    "\n",
    "question = \"What is a good book for adults with depression?\"\n",
    "hyde_rag = get_chain(hyde_retriever, llm, prompt)\n",
    "result = hyde_rag.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3b49b-2563-4a11-b9c7-7c2d82b94d23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c5dc3-d758-406b-a3c8-f6648598ad0b",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Ragas evaluators are used to measure performance of Retrievers on a synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd716d49-0dde-46b8-a27c-e13add4cd8e3",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "fc33fbe6-3350-4297-b045-23d19d131d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from ragas.integrations.langchain import EvaluatorChain\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "# create eval chains\n",
    "eval_chains = {\n",
    "    m.name: EvaluatorChain(metric=m) \n",
    "    for m in [faithfulness, answer_relevancy, context_precision, context_recall]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6e71cd6d-c1e9-4086-8fc1-daf4f43031e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "def evaluate(sample):\n",
    "    metrics = {}\n",
    "    for name, eval_chain in eval_chains.items():\n",
    "        score_name = f\"{name}_score\"\n",
    "        metrics[score_name] = eval_chain(sample)[name]\n",
    "        # print(f\"{score_name}: {metrics[score_name]}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234489d0-909d-4fbd-971a-742eebd1c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect metrics\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def get_metrics(results: List[Dict]): \n",
    "    metrics = []\n",
    "    for res in tqdm(results):\n",
    "        sample= {\n",
    "            \"question\": res[\"query\"],\n",
    "            \"answer\": res[\"result\"],\n",
    "            \"contexts\": [context.page_content for context in res[\"source_documents\"]],\n",
    "            \"ground_truth\": res[\"ground_truth\"],\n",
    "        }\n",
    "        metrics.append(evaluate(sample))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a39289-57c5-45ff-93f2-17effc47c078",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "86f80f09-bae2-4f37-8853-f505bab2688e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Book: Jami' At-Tirmidhi\\nDescription:</td>\n",
       "      <td>What is the name of the book described?\\n</td>\n",
       "      <td>Jami' At-Tirmidhi</td>\n",
       "      <td>../datasets/books/data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book: Permanent Record\\nDescription: Edward Sn...</td>\n",
       "      <td>Who is the author of the book \"Permanent Recor...</td>\n",
       "      <td>Edward Snowden</td>\n",
       "      <td>../datasets/books/data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Book: A Walk Toward Jesus: Coming Through the ...</td>\n",
       "      <td>Who is the author of the book \"A Walk Toward J...</td>\n",
       "      <td>Pamela S. Valerio</td>\n",
       "      <td>../datasets/books/data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Description: The Works of Edgar Allen Poe incl...</td>\n",
       "      <td>What famous authors' works are included alongs...</td>\n",
       "      <td>Mark Twain, Robert Louis Stevenson, Charles Di...</td>\n",
       "      <td>../datasets/books/data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Description: **** 5 out of 5 Star Rating from ...</td>\n",
       "      <td>Who is the author of the book \"The Weapon of M...</td>\n",
       "      <td>Ambrose V. Bruno</td>\n",
       "      <td>../datasets/books/data.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0              Book: Jami' At-Tirmidhi\\nDescription:   \n",
       "1  Book: Permanent Record\\nDescription: Edward Sn...   \n",
       "2  Book: A Walk Toward Jesus: Coming Through the ...   \n",
       "3  Description: The Works of Edgar Allen Poe incl...   \n",
       "4  Description: **** 5 out of 5 Star Rating from ...   \n",
       "\n",
       "                                            question  \\\n",
       "0          What is the name of the book described?\\n   \n",
       "1  Who is the author of the book \"Permanent Recor...   \n",
       "2  Who is the author of the book \"A Walk Toward J...   \n",
       "3  What famous authors' works are included alongs...   \n",
       "4  Who is the author of the book \"The Weapon of M...   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                  Jami' At-Tirmidhi   \n",
       "1                                     Edward Snowden   \n",
       "2                                  Pamela S. Valerio   \n",
       "3  Mark Twain, Robert Louis Stevenson, Charles Di...   \n",
       "4                                   Ambrose V. Bruno   \n",
       "\n",
       "                   source_doc  \n",
       "0  ../datasets/books/data.csv  \n",
       "1  ../datasets/books/data.csv  \n",
       "2  ../datasets/books/data.csv  \n",
       "3  ../datasets/books/data.csv  \n",
       "4  ../datasets/books/data.csv  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_df = pd.read_csv(EVAL_PATH)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a53afa5e-f4d8-4bae-a863-877336ad2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = eval_df[\"question\"].to_list()\n",
    "eval_answers = eval_df[\"answer\"].to_list()\n",
    "\n",
    "examples = [\n",
    "    {\"query\": q, \"ground_truth\": eval_answers[i]}\n",
    "    for i, q in enumerate(eval_questions)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "54726573-26d6-4ac2-a78f-1f6f6cc6c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "examples = random.sample(examples, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370a953-a148-4508-a776-45633a2b60b3",
   "metadata": {},
   "source": [
    "### Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "89f14169-e627-49eb-a523-84ce5813ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost/compute intensive\n",
    "\n",
    "results = naive_rag.batch(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8168ff3-ed9d-44cf-8af2-cd6b490220c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost/compute intensive\n",
    "\n",
    "metrics = get_metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "96f60613-f196-46ca-a7da-24d4a52e3d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faithfulness_score         0.943478\n",
       "answer_relevancy_score     0.959450\n",
       "context_precision_score    0.951667\n",
       "context_recall_score       0.920000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_metrics_df = pd.DataFrame(metrics)\n",
    "naive_metrics_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f89da9-6ff1-4c9d-95f1-a3d3d3b35e44",
   "metadata": {},
   "source": [
    "### HyDE RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "efcf4fd1-28fd-4203-873e-ae2e9a1f8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost/compute intensive\n",
    "\n",
    "results = hyde_rag.batch(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20fb9c4-dfd9-433c-b4db-6a74c9caeff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost/compute intensive\n",
    "\n",
    "metrics = get_metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "21e1e323-9030-4ba4-9b46-6507632f7cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c4ee85520e41fbb0d6d39b7d6ee7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n"
     ]
    }
   ],
   "source": [
    "# Cost/compute intensive\n",
    "# evaluate\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "metrics = []\n",
    "for res in tqdm(results):\n",
    "    sample= {\n",
    "        \"question\": res[\"query\"],\n",
    "        \"answer\": res[\"result\"],\n",
    "        \"contexts\": [context.page_content for context in res[\"source_documents\"]],\n",
    "        \"ground_truth\": res[\"ground_truth\"],\n",
    "    }\n",
    "    metrics.append(evaluate(sample))\n",
    "    # eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "8b21bad3-5622-4280-bd0c-577e5267ce8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faithfulness_score         0.840635\n",
       "answer_relevancy_score     0.856820\n",
       "context_precision_score    0.848333\n",
       "context_recall_score       0.820000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyde_metrics_df = pd.DataFrame(metrics)\n",
    "hyde_metrics_df.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
